{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Generate article with prompt"
      ],
      "metadata": {
        "id": "35GYySDmqDh5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SDK/Packages"
      ],
      "metadata": {
        "id": "uhhkVQZbXXIP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --quiet google-genai langgraph langchain \\\n",
        "langchain-google-genai langchain-community tavily-python pydantic"
      ],
      "metadata": {
        "id": "l2aZbhO4RTP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython\n",
        "from IPython.display import Markdown, display, Image\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)\n",
        "\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "import os\n",
        "os.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "BLvXGCo0RTfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import LLMChain\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_community.tools import TavilySearchResults\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI"
      ],
      "metadata": {
        "id": "nG_RTiqRdEkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' init gemini model and search tool '''\n",
        "model = ChatGoogleGenerativeAI(model=ModelId, temperature=0)\n",
        "tavily_tool = TavilySearchResults(max_results=5)\n",
        "\n",
        "''' define templates and runnables '''\n",
        "outline_template = ChatPromptTemplate.from_template(\n",
        "    'Create a detailed outline for an essay on {topic}')\n",
        "\n",
        "''' research web search '''\n",
        "def research_fn(topic):\n",
        "  response = tavily_tool.invoke({'query': topic})\n",
        "  return \"\\n\".join(f\"- {result['content']}\" for result in response)\n",
        "\n",
        "writing_template = ChatPromptTemplate.from_template(\n",
        "    'based on the outline and research, write a 3-paragraph essay on {topic}\\\n",
        "    :\\n\\nOutline:\\n{outline}\\n\\nResearch:\\n{research}\\n\\nEssay'\n",
        ")\n",
        "''' individual chains '''\n",
        "outline_chain = LLMChain(llm=model, prompt=outline_template)\n",
        "writing_chain = LLMChain(llm=model, prompt=writing_template)\n",
        "\n",
        "''' pipeline operator to combine chains '''\n",
        "chain = (\n",
        "    outline_chain\n",
        "    |(\n",
        "        lambda result: {\n",
        "            'topic': result['topic'],\n",
        "            'outline': result['text'],\n",
        "            'research': research_fn(result['topic']),\n",
        "        }\n",
        "    )\n",
        "    | writing_chain\n",
        "    | (lambda result: result['text'])\n",
        "    | StrOutputParser()\n",
        ")"
      ],
      "metadata": {
        "id": "zHGvfIYbRTy1",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate article"
      ],
      "metadata": {
        "id": "cHdODXpYg-gR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "article = chain.invoke({'topic': prompt})\n",
        "article"
      ],
      "metadata": {
        "id": "0BxHEQJtRUPn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}